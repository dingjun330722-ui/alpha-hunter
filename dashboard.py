import streamlit as st
import requests
import feedparser
from openai import OpenAI
import datetime
import concurrent.futures
import json
import os
import socket

# ================== é¡µé¢é…ç½® ==================
st.set_page_config(page_title="Alpha Hunter V2.5 (äº‘ç«¯å¢å¼ºç‰ˆ)", page_icon="âš¡", layout="wide")

# å…¨å±€è¶…æ—¶è®¾ç½®
socket.setdefaulttimeout(30)

# ä¼ªè£…æˆçœŸå®çš„æµè§ˆå™¨ï¼ˆè¿™æ˜¯å…³é”®ï¼‰
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

# è‡ªå®šä¹‰ CSS
st.markdown("""
<style>
    .card { background-color: #f0f2f6; border-radius: 10px; padding: 20px; border-left: 5px solid #ff4b4b; margin-bottom: 20px; color: #31333F; }
    .card-title { font-size: 18px; font-weight: bold; margin-bottom: 10px; }
    .card-content { font-size: 14px; line-height: 1.6; }
    .card-source { font-size: 12px; color: #666; margin-top: 15px; font-style: italic; }
    .stButton>button { width: 100%; }
</style>
""", unsafe_allow_html=True)

# ================== é…ç½®ç®¡ç† ==================
SOURCE_FILE = "sources.json"
CONFIG_FILE = "config.json"

DEFAULT_CONFIG = {
    "api_url": "https://new.wuxuai.com/v1",
    "api_key": "",
    "proxy_url": "", 
    "models": ["gemini-2.5-pro", "gpt-4o", "glm-4-flash"],
    "selected_model": "gemini-2.5-pro"
}

def load_config():
    if not os.path.exists(CONFIG_FILE): return DEFAULT_CONFIG
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f: return json.load(f)
    except: return DEFAULT_CONFIG

def save_config(config_data):
    with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
        json.dump(config_data, f, ensure_ascii=False, indent=4)

if 'app_config' not in st.session_state:
    st.session_state.app_config = load_config()

def update_config_key(key, value):
    st.session_state.app_config[key] = value
    save_config(st.session_state.app_config)

# ================== æ ¸å¿ƒï¼šå¢å¼ºå‹æŠ“å–å‡½æ•° ==================
def fetch_feed_data(url, proxy):
    """
    ä½¿ç”¨ Requests åº“è¿›è¡Œå¼ºåŠ›æŠ“å–ï¼Œç»•è¿‡åçˆ¬è™«
    """
    proxies = None
    if proxy and proxy.strip():
        proxies = {"http": proxy, "https": proxy}
    
    try:
        # ç¬¬ä¸€å±‚å°è¯•ï¼šç›´æ¥ç”¨ feedparser
        d = feedparser.parse(url) # ä¸å¸¦ headers å…ˆè¯•ä¸€æ¬¡
        if d.entries:
            return d
            
        # ç¬¬äºŒå±‚å°è¯•ï¼šæ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚
        response = requests.get(url, headers=HEADERS, proxies=proxies, timeout=20)
        response.raise_for_status()
        # å°†ä¸‹è½½çš„å†…å®¹å–‚ç»™ feedparser
        return feedparser.parse(response.content)
        
    except Exception as e:
        raise e

# ================== AI åˆ†ææ ¸å¿ƒ ==================
def analyze_single_source(source, model, key, url, sys_prompt, proxy):
    result = {"source": source["name"], "status": "failed", "data": None, "error": None}
    
    if not source.get("enabled", True):
        result["status"] = "skipped"
        return result

    try:
        # === æ ¸å¿ƒæ”¹åŠ¨ï¼šä½¿ç”¨å¢å¼ºç‰ˆæŠ“å– ===
        feed = fetch_feed_data(source["url"], proxy)
        
        if not feed.entries:
            result["status"] = "empty" # çœŸçš„æ²¡æŠ“åˆ°å†…å®¹
            return result
            
        entry = feed.entries[0]
        content_snippet = entry.get('summary', '')[:800]
        if len(content_snippet) < 10: content_snippet = entry.title 

        # å³ä½¿æŠ“å–æˆåŠŸï¼Œå¦‚æœ Key æ²¡å¡«å¯¹ï¼ŒAI ä¹Ÿä¼šæŠ¥é”™ï¼Œè¿™é‡ŒåŠ ä¸ªåˆ¤æ–­
        if not key:
            raise Exception("æœªå¡«å†™ API Key")

        # è°ƒç”¨ AI
        client = OpenAI(api_key=key, base_url=url)
        
        user_prompt = f"ã€æ ‡é¢˜ã€‘ï¼š{entry.title}\nã€å†…å®¹æ‘˜è¦ã€‘ï¼š{content_snippet}"
        
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_prompt}
            ],
            timeout=20 
        )
        
        result["status"] = "success"
        result["data"] = {
            "title": entry.title,
            "link": entry.link,
            "summary": entry.get('summary', 'æ— æ‘˜è¦'),
            "ai_analysis": resp.choices[0].message.content,
        }
        return result
    except Exception as e:
        result["error"] = str(e)
        return result

# ================== ä¾§è¾¹æ  ==================
with st.sidebar:
    st.header("âš™ï¸ äº‘ç«¯æ§åˆ¶å°")
    
    with st.expander("ğŸ”Œ è¿æ¥é…ç½®", expanded=True):
        api_url = st.text_input("æ¥å£åœ°å€", value=st.session_state.app_config.get("api_url"), key="input_url", on_change=lambda: update_config_key("api_url", st.session_state.input_url))
        api_key = st.text_input("API å¯†é’¥", type="password", value=st.session_state.app_config.get("api_key"), key="input_key", on_change=lambda: update_config_key("api_key", st.session_state.input_key))
        
        # ä»£ç†è®¾ç½®ï¼ˆé‡ç‚¹æç¤ºï¼‰
        st.markdown("---")
        proxy_url = st.text_input("HTTP ä»£ç† (äº‘ç«¯è¯·ç•™ç©ºï¼)", value=st.session_state.app_config.get("proxy_url", ""), placeholder="æœ¬åœ°å¡« http://127.0.0.1:7890ï¼Œäº‘ç«¯å¿…é¡»ä¸ºç©º", key="input_proxy", on_change=lambda: update_config_key("proxy_url", st.session_state.input_proxy))
        if proxy_url and "127.0.0.1" in proxy_url:
            st.warning("âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ°ä½ åœ¨äº‘ç«¯ä½¿ç”¨äº†æœ¬åœ°ä»£ç†åœ°å€ï¼Œè¿™ä¼šå¯¼è‡´æ— æ³•è¿æ¥ï¼è¯·æ¸…ç©ºæ­¤æ ã€‚")

    st.markdown("### ğŸ¤– æ¨¡å‹æ§åˆ¶")
    model_list = st.session_state.app_config.get("models", ["gemini-2.5-pro"])
    current_model = st.session_state.app_config.get("selected_model")
    index = model_list.index(current_model) if current_model in model_list else 0
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", model_list, index=index, key="model_select", on_change=lambda: update_config_key("selected_model", st.session_state.model_select))
    
    # ç®€å•çš„åˆ·æ–°æŒ‰é’®
    if st.button("ğŸ”„ åˆ·æ–°æ¨¡å‹åº“"):
         try:
            # åˆ·æ–°æ—¶ä¸èµ°ä»£ç†ï¼Œé™¤éç”¨æˆ·å¼ºè¡Œå¡«äº†
            headers = {"Authorization": f"Bearer {api_key}"}
            res = requests.get(f"{api_url.rstrip('/')}/models", headers=headers, timeout=10)
            if res.status_code == 200:
                data = res.json()
                models = [item['id'] for item in data['data']] if 'data' in data else [item['id'] for item in data]
                st.session_state.app_config["models"] = models
                save_config(st.session_state.app_config)
                st.success("åˆ·æ–°æˆåŠŸ")
                st.rerun()
         except Exception as e: st.error(f"åˆ·æ–°å¤±è´¥: {e}")

    st.divider()
    st.markdown("### ğŸ“¡ æƒ…æŠ¥æºç®¡ç†")
    if 'sources_data' not in st.session_state:
        if os.path.exists(SOURCE_FILE):
             with open(SOURCE_FILE, 'r', encoding='utf-8') as f: st.session_state.sources_data = json.load(f)
        else: st.session_state.sources_data = [{"name": "OpenAI Blog", "url": "https://openai.com/index.xml", "enabled": True}]

    edited_sources = st.data_editor(st.session_state.sources_data, num_rows="dynamic", column_config={"name": "ä¿¡æºåç§°","url": st.column_config.LinkColumn("RSSé“¾æ¥"),"enabled": st.column_config.CheckboxColumn("å¯ç”¨", default=True)}, key="editor")
    if edited_sources != st.session_state.sources_data:
        st.session_state.sources_data = edited_sources
        with open(SOURCE_FILE, 'w', encoding='utf-8') as f: json.dump(edited_sources, f, ensure_ascii=False, indent=4)

    st.divider()
    default_prompt = "ä½ æ˜¯ä¸€ä¸ªåå°”è¡—é¡¶çº§æƒ…æŠ¥å®˜ã€‚å¯¹æ¯æ¡æ¶ˆæ¯è¿›è¡Œè¯„åˆ†(0-10)ã€‚ç»™å‡ºç®€ç»ƒçš„ã€é€»è¾‘é“¾ã€‘æ¨æ¼”å’Œã€äº¤æ˜“å»ºè®®ã€‘(Long/Short)ã€‚é£æ ¼æåº¦æ¯’èˆŒã€åŠŸåˆ©ã€‚"
    system_prompt = st.text_area("AI äººè®¾æŒ‡ä»¤", value=default_prompt, height=100)

# ================== ä¸»ç•Œé¢ ==================
st.title("âš¡ Alpha Hunter V2.5 (äº‘ç«¯å¼ºåŠ›ç‰ˆ)")

if st.button("ğŸš€ æé€Ÿæ‰«æ (TURBO SCAN)", type="primary"):
    active_sources = [s for s in st.session_state.sources_data if s.get('enabled', True)]
    
    if not active_sources:
        st.warning("è¯·å…ˆæ·»åŠ æƒ…æŠ¥æºï¼")
    else:
        results_container = st.container()
        progress_bar = st.progress(0)
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            future_to_source = {
                executor.submit(analyze_single_source, source, selected_model, api_key, api_url, system_prompt, proxy_url): source 
                for source in active_sources
            }
            
            completed = 0
            for future in concurrent.futures.as_completed(future_to_source):
                res = future.result()
                completed += 1
                progress_bar.progress(completed / len(active_sources))
                
                if res["status"] == "success":
                    data = res["data"]
                    with results_container:
                        c1, c2 = st.columns([1.5, 1])
                        with c2:
                            st.subheader(f"ğŸ“„ {res['source']}")
                            st.markdown(f"[{data['title']}]({data['link']})")
                            with st.expander("æ‘˜è¦"): st.write(data['summary'])
                            html_card = f"""<div class="card"><div class="card-title">{data['title']}</div><div class="card-content">{data['summary'][:150]}...</div><div class="card-source">Source: {res['source']}</div></div>"""
                            st.markdown(html_card, unsafe_allow_html=True)
                        with c1:
                            st.subheader("ğŸ¤– åˆ†ææŠ¥å‘Š")
                            st.info(data['ai_analysis'])
                        st.divider()
                elif res["status"] == "failed":
                    st.error(f"âŒ {res['source']}: {res['error']}")